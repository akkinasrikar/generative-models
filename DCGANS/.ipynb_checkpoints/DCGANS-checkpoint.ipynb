{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=train_images.reshape(train_images.shape[0],28,28,1).astype('float32')\n",
    "train_images=(train_images-127.5)/127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)\n",
    "    # shape 7,7,256\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    #shape 7,7,128\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    #shape 14,14,128\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "    #shape 28,28,1\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator=make_generator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise,training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x219e3303748>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00098372]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir='./training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "#print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_steps(images):\n",
    "    noise=tf.random.normal([BATCH_SIZE,noise_dim])\n",
    "    with tf.GradientTape() as gen_tape,tf.GradientTape() as dis_tape:\n",
    "        \n",
    "        generated_images=generator(noise,training=True)\n",
    "        \n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        \n",
    "        gen_loss=generator_loss(fake_output)\n",
    "        dis_loss=discriminator_loss(real_output,fake_output)\n",
    "        \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = dis_tape.gradient(dis_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset,epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start=time.time()\n",
    "        \n",
    "        for image_batch in dataset:\n",
    "            train_steps(image_batch)\n",
    "        \n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator,epoch + 1,seed)\n",
    "        \n",
    "        if (epoch + 1) % 15 == 0:\n",
    "              checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "                \n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "        \n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,epochs,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-d152560ca122>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-79611ec0f615>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mtrain_steps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
